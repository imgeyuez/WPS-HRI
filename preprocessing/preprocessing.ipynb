{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches_dir = '../data/wps_speeches'\n",
    "speeches = [f for f in os.listdir(speeches_dir) if f.endswith('.txt')]\n",
    "\n",
    "speeches_list = []\n",
    "\n",
    "def sort_speeches(filename):\n",
    "    session_match = re.search(r'SPV\\.\\d+(Resumption\\d+)?', filename)  # Match session and resumption\n",
    "    speech_match = re.search(r'spch(\\d+)', filename)  # Match speech number\n",
    "    session = session_match.group(0) if session_match else ''\n",
    "    speech_num = int(speech_match.group(1)) if speech_match else float('inf')  # Default speech number if missing\n",
    "    return session, speech_num\n",
    "    \n",
    "sorted_speeches = sorted(speeches, key=sort_speeches)\n",
    "\n",
    "for speech in sorted_speeches:\n",
    "    file_path = os.path.join(speeches_dir, speech)\n",
    "    try:\n",
    "        with open(file_path, encoding='utf-8-sig') as f:\n",
    "            text = f.read()\n",
    "    except UnicodeDecodeError:\n",
    "        try:\n",
    "            with open(file_path, encoding='utf-16') as f: # trying alternative encoding\n",
    "                text = f.read()\n",
    "        except Exception as e:\n",
    "            print(f\"Could not read {file_path}: {e}\")\n",
    "            continue\n",
    "    year_match = re.search(r'(\\d{4})', speech)\n",
    "    year = year_match.group(1) if year_match else None\n",
    "    \n",
    "    # Append both text and metadata\n",
    "    speeches_list.append({'filename': speech, 'text': text, 'year': year})\n",
    "\n",
    "speeches_df = pd.DataFrame(speeches_list, columns=['text', 'year', 'filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove new line characters\n",
    "speeches_df['text'] = speeches_df['text'].str.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4668, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count rows\n",
    "speeches_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv\n",
    "speeches_df.to_csv('../data/wps_speeches.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
