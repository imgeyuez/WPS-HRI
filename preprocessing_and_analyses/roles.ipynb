{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\imgey\\Desktop\\MASTER_POTSDAM\\WiSe2425\\PM1_argument_mining\\wps_venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\imgey\\Desktop\\MASTER_POTSDAM\\WiSe2425\\PM1_argument_mining\\wps_venv\\lib\\site-packages\\transformers\\utils\\generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('This', 'PRON'), ('is', 'AUX'), ('a', 'DET'), ('sentence', 'NOUN'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "nlp = en_core_web_sm.load()\n",
    "doc = nlp(\"This is a sentence.\")\n",
    "print([(w.text, w.pos_) for w in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dependency_parsing(text):\n",
    "    '''\n",
    "    Function which:\n",
    "    1) Sentence tokenizes the given input text,\n",
    "    2) Tokenizes the sentences into tokens,\n",
    "    3) POS-tags, and\n",
    "    4) Parses the dependencies of the text.\n",
    "    '''\n",
    "    document = nlp(text)  # Process the entire text once\n",
    "\n",
    "    # Iterate over sentences\n",
    "    for sentence in document.sents:\n",
    "        print(f\"Sentence: {sentence.text}\")\n",
    "        print(f\"{'Token':<15} {'Head':<15} {'Dependency':<15}\")\n",
    "        print(\"-\" * 45)\n",
    "\n",
    "        # Iterate over tokens in the sentence\n",
    "        for token in sentence:\n",
    "            print(f\"{token.text:<15} {token.head.text:<15} {token.dep_:<15}\")\n",
    "        print()  # Blank line between sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: We commend the work that has been done by the United Nations Children's Fund in reintegration projects that has led to the release of girls from the armed forces in various countries.\n",
      "Token           Head            Dependency     \n",
      "---------------------------------------------\n",
      "We              commend         nsubj          \n",
      "commend         commend         ROOT           \n",
      "the             work            det            \n",
      "work            commend         dobj           \n",
      "that            done            nsubjpass      \n",
      "has             done            aux            \n",
      "been            done            auxpass        \n",
      "done            work            relcl          \n",
      "by              done            agent          \n",
      "the             Fund            det            \n",
      "United          Nations         compound       \n",
      "Nations         Fund            compound       \n",
      "Children        Fund            poss           \n",
      "'s              Children        case           \n",
      "Fund            by              pobj           \n",
      "in              done            prep           \n",
      "reintegration   projects        compound       \n",
      "projects        in              pobj           \n",
      "that            led             nsubj          \n",
      "has             led             aux            \n",
      "led             projects        relcl          \n",
      "to              led             prep           \n",
      "the             release         det            \n",
      "release         to              pobj           \n",
      "of              release         prep           \n",
      "girls           of              pobj           \n",
      "from            release         prep           \n",
      "the             forces          det            \n",
      "armed           forces          amod           \n",
      "forces          from            pobj           \n",
      "in              forces          prep           \n",
      "various         countries       amod           \n",
      "countries       in              pobj           \n",
      ".               commend         punct          \n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = \"We commend the work that has been done by the United Nations Children's Fund in reintegration projects that has led to the release of girls from the armed forces in various countries.\"\n",
    "\n",
    "dependency_parsing(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The agent is We\n",
      "The patient is work\n",
      "The recipient is Fund\n",
      "The recipient is projects\n",
      "The agent is that\n",
      "The recipient is release\n",
      "The recipient is girls\n",
      "The recipient is forces\n",
      "The recipient is countries\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"We commend the work that has been done by the United Nations Children's Fund in reintegration projects that has led to the release of girls from the armed forces in various countries.\")\n",
    "\n",
    "for t in doc:\n",
    "  if t.dep_ == \"nsubj\":\n",
    "    print(f\"The agent is {t.text}\")\n",
    "  # direktes objekt\n",
    "  elif t.dep_ == \"dobj\":\n",
    "    print(f\"The patient is {t.text}\")\n",
    "    # objekt mit prÃ¤position\n",
    "  elif t.dep_ == \"pobj\":\n",
    "    print(f\"The recipient is {t.text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wps_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
